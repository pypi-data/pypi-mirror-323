{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "import random\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deeptensor import (\n",
                "    SGD,\n",
                "    AdaGrad,\n",
                "    Adam,\n",
                "    LinearLayer,\n",
                "    GeLu,\n",
                "    LeakyReLu,\n",
                "    Model,\n",
                "    Momentum,\n",
                "    ReLu,\n",
                "    RMSprop,\n",
                "    Sigmoid,\n",
                "    SoftMax,\n",
                "    Tanh,\n",
                "    Tensor,\n",
                "    Value,\n",
                "    cross_entropy,\n",
                "    mean_squared_error,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(1337)\n",
                "random.seed(1337)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make up a dataset\n",
                "\n",
                "from sklearn.datasets import make_moons, make_blobs\n",
                "\n",
                "X, y = make_moons(n_samples=100, noise=0.1)\n",
                "\n",
                "# y_new = y * 2 - 1  # make y be -1 or 1\n",
                "# visualize in 2D\n",
                "plt.figure(figsize=(5, 5))\n",
                "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap=\"jet\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X[0], y[0], X[1], y[1], X[2], y[2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# initialize a model\n",
                "model = Model(\n",
                "    [\n",
                "        LinearLayer(2, 16),\n",
                "        ReLu(),\n",
                "        LinearLayer(16, 16),\n",
                "        ReLu(),\n",
                "        LinearLayer(16, 2),\n",
                "    ],\n",
                "    False,  # using_cuda\n",
                ")\n",
                "\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = Adam(model, 0.001)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# loss function\n",
                "def my_loss_fn():\n",
                "    scores = []\n",
                "    total_loss = 0\n",
                "    accuracy = []\n",
                "    real_output_ohe = Tensor([2])  # one_hot_encoded\n",
                "    for i in range(2):\n",
                "        real_output_ohe.set(i, Value(0))\n",
                "\n",
                "    for idx, x in enumerate(X):\n",
                "        inp_tensor = Tensor([2])\n",
                "        inp_tensor.set(0, Value(x[0]))\n",
                "        inp_tensor.set(1, Value(x[1]))\n",
                "        out = model(inp_tensor)\n",
                "        real_output_ohe.set(y[idx], Value(1))\n",
                "        # print(f\"{out=}; {out.get(0)=}; {out.get(1)=}; {real_output_ohe=}\")\n",
                "        losses = cross_entropy(out, real_output_ohe)\n",
                "        # print(f\"{losses=}\")\n",
                "        real_output_ohe.set(y[idx], Value(0))\n",
                "\n",
                "        total_loss += losses.data\n",
                "        # print(\"-- going for backprop --\")\n",
                "        # Backpropagation\n",
                "        losses.backward()\n",
                "        optimizer.step()\n",
                "        optimizer.zero_grad()\n",
                "        # # Also get accuracy\n",
                "        if (out.get(0).data > out.get(1).data and y[idx] == 0) or (\n",
                "            out.get(0).data < out.get(1).data and y[idx] == 1\n",
                "        ):\n",
                "            accuracy.append(1)\n",
                "        else:\n",
                "            accuracy.append(0)\n",
                "\n",
                "    return total_loss, sum(accuracy) / len(accuracy)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_loss, acc = my_loss_fn()\n",
                "\n",
                "acc, total_loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# optimization\n",
                "for k in range(200):\n",
                "    # forward\n",
                "    total_loss, acc = my_loss_fn()\n",
                "\n",
                "    print(f\"step {k} loss {total_loss}, accuracy {acc*100}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# visualize decision boundary\n",
                "\n",
                "h = 0.25\n",
                "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
                "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
                "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
                "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
                "inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n",
                "\n",
                "tensor_input = [Tensor([2]) for _ in range(len(inputs))]\n",
                "for i in range(len(inputs)):\n",
                "    tensor_input[i].set(0, inputs[i][0])\n",
                "    tensor_input[i].set(1, inputs[i][1])\n",
                "\n",
                "scores = list(map(model, tensor_input))\n",
                "Z = np.array([s.get(0).data > 0 for s in scores])\n",
                "Z = Z.reshape(xx.shape)\n",
                "\n",
                "fig = plt.figure()\n",
                "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
                "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
                "plt.xlim(xx.min(), xx.max())\n",
                "plt.ylim(yy.min(), yy.max())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
