Metadata-Version: 2.3
Name: samv2_webcam
Version: 0.0.3
Summary: CPU compatible fork of the official SAMv2 implementation with Webcam support
Keywords: deep-learning,pytorch
Author-email: Sonny Kurniawan <sonny.kurniawan.yap@gmail.com>
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.3.1
Requires-Dist: torchvision>=0.18.1
Requires-Dist: numpy>=1.24.4
Requires-Dist: tqdm>=4.66.1
Requires-Dist: hydra-core>=1.3.2
Requires-Dist: iopath>=0.1.10
Requires-Dist: pillow>=9.4.0
Requires-Dist: samv2[test, dev] ; extra == "all"
Requires-Dist: black ; extra == "dev"
Requires-Dist: isort ; extra == "dev"
Requires-Dist: pre-commit>=2.18.0 ; extra == "dev"
Requires-Dist: pytest ; extra == "test"
Project-URL: homepage, https://github.com/sonnyky/samv2
Project-URL: repository, https://github.com/sonnyky/samv2
Provides-Extra: all
Provides-Extra: dev
Provides-Extra: test

<a href="https://colab.research.google.com/github/SauravMaheshkar/samv2/blob/main/examples/notebooks/samv2_prompted_segmentation_with_wandb_tables.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
[![Build and Tests](https://github.com/SauravMaheshkar/samv2/actions/workflows/ci.yml/badge.svg)](https://github.com/SauravMaheshkar/samv2/actions/workflows/ci.yml) [![](https://img.shields.io/badge/Weights_&_Biases-FFCC33?&logo=WeightsAndBiases&logoColor=black)](https://wandb.ai/sauravmaheshkar/samv2)

CPU **compatible** fork of the official SAMv2 implementation with webcam support.

## Features ðŸš€

* CPU compatible
* ships with config files
* Run image and video, and webcam inference on CPUs
* [Example notebooks](../examples/notebooks/) showcasing inference using weights and biases.

## Installation

You can download it from [pypi](https://pypi.org/) using `pip` as follows:

```bash
pip install samv2-webcam
```

or from the repository:

```bash
pip install git+https://github.com/sonnyky/samv2.git
```

## Usage

After downloading the official weights, you can use the `load_model()` helper method to instantiate a model.

```python
from sam2 import load_model

model = load_model(
    variant="tiny",
    ckpt_path="artifacts/sam2_hiera_tiny.pt",
    device="cpu"
)
```

* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SauravMaheshkar/samv2/blob/main/examples/notebooks/samv2_prompted_segmentation_with_wandb_tables.ipynb) Example Notebook to run prompted segmentation on images logging predictions as W&B Tables.
* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SauravMaheshkar/samv2/blob/main/examples/notebooks/samv2_automatic_segmentation_with_wandb_tables.ipynb) Example Notebook to run automatic segmentation on images logging predictions as W&B Tables.

## Citation

```bibtex
@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint},
  year={2024}
}
```

