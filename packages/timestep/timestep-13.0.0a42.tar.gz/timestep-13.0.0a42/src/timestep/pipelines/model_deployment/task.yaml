envs:
  HF_TOKEN: null
  MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING: true
  MLFLOW_TRACKING_URI: http://mlflow-tracking.mlflow.svc.cluster.local:80
  MLFLOW_TRACKING_USERNAME: user
  MLFLOW_TRACKING_PASSWORD: null
  PYENV_VERSION: 3.10.13

resources:
  cloud: kubernetes
  cpus: 2+
  image_id: docker:ros:jazzy-ros-base-noble
  memory: 2+
  ports: 8000

run: |
  set -ex # Echo commands and exit on first error

  # Since SkyPilot tasks are run inside a fresh conda "(base)" environment,
  # deactivate first to access what the Docker image has already installed.
  conda deactivate

  source .venv/bin/activate

  nvcc -V
  nvidia-smi

  # mlflow ...

setup: |
  set -ex # Echo commands and exit on first error

  # Since SkyPilot tasks are run inside a fresh conda "(base)" environment,
  # deactivate first to access what the Docker image has already installed.
  conda deactivate

  sudo apt-get update && DEBIAN_FRONTEND=noninteractive sudo apt-get install -y \
    build-essential \
    ccache \
    curl \
    git \
    libbz2-dev \
    libcurl4-openssl-dev \
    libffi-dev \
    liblzma-dev \
    libncursesw5-dev \
    libreadline-dev \
    libsqlite3-dev \
    libssl-dev \
    libxml2-dev \
    libxmlsec1-dev \
    nvidia-cuda-toolkit \
    nvidia-modprobe \
    python3.12-venv \
    software-properties-common \
    tk-dev \
    xz-utils \
    zlib1g-dev

  # If pyenv is not installed, install it
  if [ ! -d ~/.pyenv ]; then
    curl https://pyenv.run | bash
    echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.bashrc
    echo '[[ -d $PYENV_ROOT/bin ]] && export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.bashrc
    echo 'eval "$(pyenv init -)"' >> ~/.bashrc
    echo 'eval "$(pyenv virtualenv-init -)"' >> ~/.bashrc
    source ~/.bashrc
  fi

  pyenv install --skip-existing $PYENV_VERSION
  pyenv global $PYENV_VERSION

  python --version
  python -m venv .venv
  source .venv/bin/activate

  pip install --upgrade pip
  # pip install -r requirements.txt

  python -c "import torch; print(torch.cuda.is_available())"
  python -c "import torch; print(torch.version.cuda)"

workdir: src/timestep/pipelines/model_deployment
