{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "\n",
    "from primeGraph.buffer.factory import History, Incremental, LastValue\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution plan conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    print(\"g \\n\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"b\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"c\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"e\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    time.sleep(1)\n",
    "    print(\"g\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"c\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"e\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "# Create a test graph with a mix of parallel and sequential paths\n",
    "test_graph = Graph()\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def start_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting workflow \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_1():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 1 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 1 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_2():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 2 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 2 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def final_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Running final task \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# Create a workflow with parallel execution\n",
    "test_graph.add_edge(START, \"start_task\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_1\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_2\")\n",
    "test_graph.add_edge(\"parallel_task_1\", \"final_task\")\n",
    "test_graph.add_edge(\"parallel_task_2\", \"final_task\")\n",
    "test_graph.add_edge(\"final_task\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "print(\"\\nExecution Plan:\")\n",
    "rprint(test_graph.execution_plan)\n",
    "print(\"\\nStarting execution:\")\n",
    "start_time = time.time()\n",
    "test_graph.execute()\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node()\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(f\"Counter: {test_graph.state.counter}\")  # Should be 8 (5 + 3)\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should contain both metric updates\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.constants import END, START\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@test_graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_status(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "# Create the workflow with parallel execution\n",
    "test_graph.add_edge(START, \"increment_counter\")\n",
    "test_graph.add_edge(START, \"decrement_counter\")\n",
    "test_graph.add_edge(START, \"update_status\")\n",
    "test_graph.add_edge(\"increment_counter\", END)\n",
    "test_graph.add_edge(\"decrement_counter\", END)\n",
    "test_graph.add_edge(\"update_status\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(\n",
    "    f\"Counter: {test_graph.state.counter}\"\n",
    ")  # Should reflect the net effect of increments and decrements\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should be empty as no metrics are updated\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"in_progress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(\"process_data\", \"validate\")\n",
    "graph.add_edge(\"validate\", \"escape\")\n",
    "graph.add_edge(\"escape\", \"prep\")\n",
    "graph.add_edge(\"validate\", \"aa\")\n",
    "graph.add_edge(\"aa\", \"bb\")\n",
    "graph.add_edge(\"bb\", \"prep\")\n",
    "graph.add_edge(\"prep\", END)\n",
    "\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "\n",
    "\n",
    "graph.start(timeout=10)\n",
    "\n",
    "rprint(graph.state)\n",
    "\n",
    "# Assert final state\n",
    "assert (\n",
    "    graph.state.counter == 1\n",
    "), \"Counter should reflect net effect of increments and decrements\"\n",
    "assert graph.state.status == \"complete\", \"Status should be 'complete'\"\n",
    "assert len(graph.state.metrics) == 3, \"Metrics should contain three updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={\"xablau\": 2.0})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"counter\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"metrics\"].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(simple_graph._convert_execution_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_execution_plan(plan, metadata):\n",
    "    def slice_list(lst, meta):\n",
    "        result = []\n",
    "        for item in lst:\n",
    "            if isinstance(item, list):\n",
    "                # Recursively slice nested lists\n",
    "                sliced_item = slice_list(item, meta)\n",
    "                if sliced_item:\n",
    "                    result.append(sliced_item)\n",
    "            else:\n",
    "                # Check metadata for slicing\n",
    "                if meta.get(item) == \"before\":\n",
    "                    break\n",
    "                result.append(item)\n",
    "                if meta.get(item) == \"after\":\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    return slice_list(plan, metadata)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "execution_plan = [\n",
    "    \"process_data\",\n",
    "    \"validate\",\n",
    "    [[\"escape\", [\"dd\", \"cc\"], \"hh\"], [\"aa\", \"bb\"]],\n",
    "    \"prep\",\n",
    "]\n",
    "metadata = {\n",
    "    # 'process_data': 'after',\n",
    "    # 'validate': 'before',\n",
    "    # 'escape': 'after',\n",
    "    \"dd\": \"before\",\n",
    "    # 'cc': 'after',\n",
    "    # 'hh': 'before',\n",
    "    # 'aa': 'after',\n",
    "    # 'bb': 'before',\n",
    "    # 'prep': 'after'\n",
    "}\n",
    "\n",
    "sliced_plan = slice_execution_plan(execution_plan, metadata)\n",
    "print(sliced_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_plan[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem here is that in the case of update_status_to_complete,\n",
    "# it's not checking if the next node is a convergence point\n",
    "\n",
    "# it needs to have a function that will check if the next node\n",
    "# connector. find_convergence_point is not doing enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing interruption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = escape\n",
    "\n",
    "x.__metadata__[\"interrupt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    time.sleep(0.5)\n",
    "    print(\"escape\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    time.sleep(1.5)\n",
    "    print(\"process_data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    time.sleep(0.5)\n",
    "    print(\"validate\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    time.sleep(1.5)\n",
    "    print(\"aa\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    time.sleep(0.5)\n",
    "    print(\"bb\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    time.sleep(1.5)\n",
    "    print(\"dd\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    time.sleep(1.5)\n",
    "    print(\"cc\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    time.sleep(0.5)\n",
    "    print(\"hh\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    time.sleep(0.5)\n",
    "    print(\"prep\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "simple_graph._convert_execution_plan()\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.graph.executable import ExecutableNode\n",
    "\n",
    "\n",
    "def add_item_to_obj_store(obj_store: Union[List, Tuple], item):\n",
    "    if isinstance(obj_store, list):\n",
    "        obj_store.append(item)\n",
    "        return obj_store  # Return the modified list\n",
    "    elif isinstance(obj_store, tuple):\n",
    "        return obj_store + (item,)  # Already returns the new tuple\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object store type: {type(obj_store)}\")\n",
    "\n",
    "\n",
    "def extract_tasks_from_node(node, tasks=[]):\n",
    "    \"\"\"\n",
    "    Extracts tasks from a node, including nested nodes\n",
    "    returns lists for sequential execution and tuples for parallel execution\n",
    "    \"\"\"\n",
    "    tasks = [] if node.execution_type == \"sequential\" else tuple()\n",
    "    for task in node.task_list:\n",
    "        if isinstance(task, ExecutableNode):\n",
    "            if task.execution_type == \"sequential\":\n",
    "                tasks = add_item_to_obj_store(tasks, extract_tasks_from_node(task, []))\n",
    "            else:\n",
    "                tasks = add_item_to_obj_store(\n",
    "                    tasks, extract_tasks_from_node(task, tuple())\n",
    "                )\n",
    "        else:\n",
    "            tasks = add_item_to_obj_store(tasks, task)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "rprint(extract_tasks_from_node(simple_graph.execution_plan[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=0, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"increment_counter\")\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"decrement_counter\")\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_in_progress\")\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_complete\")\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"finalize_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "graph._convert_execution_plan()\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def task2(state):\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task3(state):\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[edge.id for edge in graph.edges if edge.end_node == \"__start__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Async Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 (testing non-async using execute_async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics=[], current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "def step_1():\n",
    "    time.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_A():\n",
    "    time.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_B():\n",
    "    time.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_2():\n",
    "    time.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "async def step_1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_A():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_B():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_2():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task1(state):\n",
    "    print(\"task1\")\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task2(state):\n",
    "    print(\"task2\")\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "async def task3(state):\n",
    "    print(\"task3\")\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task4(state):\n",
    "    print(\"task4\")\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "# Create parallel paths\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task1\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()\n",
    "\n",
    "# First execution should execute task1 and task3, but pause before task2\n",
    "# await graph.start_async()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "StateForTestWithHistory(execution_order=[\"a\", 2], counter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "ComplexTestState(counter=0, status=\"\", metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "class SimpleGraphState(GraphState):\n",
    "    messages: History[str]\n",
    "\n",
    "\n",
    "# Create state instance\n",
    "state = SimpleGraphState(messages=[])\n",
    "\n",
    "# Update graph with state\n",
    "storage = LocalStorage()\n",
    "graph1 = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_hello(state: GraphState):\n",
    "    return {\"messages\": \"Hello\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_world(state: GraphState):\n",
    "    return {\"messages\": \"World\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_exclamation(state: GraphState):\n",
    "    return {\"messages\": \"!\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "graph1.add_edge(START, \"add_hello\")\n",
    "graph1.add_edge(\"add_hello\", \"add_world\")\n",
    "graph1.add_edge(\"add_world\", \"add_exclamation\")\n",
    "graph1.add_edge(\"add_exclamation\", END)\n",
    "\n",
    "# Add nodes and edges...\n",
    "graph1.compile()\n",
    "graph1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph1.start_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage._storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Subgraph Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = Graph()\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def start_process():\n",
    "    print(\"Starting main process\")\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_process():\n",
    "    print(\"Ending main process\")\n",
    "\n",
    "\n",
    "# Create subgraph\n",
    "sub_graph = Graph()\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task1():\n",
    "    print(\"Subtask 1\")\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task2():\n",
    "    print(\"Subtask 2\")\n",
    "\n",
    "\n",
    "# Add edges to subgraph\n",
    "sub_graph.add_edge(START, \"sub_task1\")\n",
    "sub_graph.add_edge(\"sub_task1\", \"sub_task2\")\n",
    "sub_graph.add_edge(\"sub_task2\", END)\n",
    "\n",
    "\n",
    "# Add subgraph as a node to main graph\n",
    "@main_graph.subgraph(name=\"processing\")\n",
    "def processing_subgraph():\n",
    "    return sub_graph\n",
    "\n",
    "\n",
    "# Add edges to main graph including the subgraph\n",
    "main_graph.add_edge(START, \"start_process\")\n",
    "main_graph.add_edge(\"start_process\", \"processing\")  # Connect to subgraph\n",
    "main_graph.add_edge(\"processing\", \"end_process\")  # Connect from subgraph\n",
    "main_graph.add_edge(\"end_process\", END)\n",
    "\n",
    "# Compile and visualize\n",
    "main_graph.compile()\n",
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmain_graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Create a subgraph\n",
    "@main_graph.subgraph()\n",
    "def processing_subgraph():\n",
    "    subgraph = Graph(state=state)\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_a(state):\n",
    "        return {\"execution_order\": \"process_a\", \"counter\": 1}\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_b(state):\n",
    "        return {\"execution_order\": \"process_b\", \"counter\": 2}\n",
    "\n",
    "    subgraph.add_edge(START, \"process_a\")\n",
    "    subgraph.add_edge(\"process_a\", \"process_b\")\n",
    "    subgraph.add_edge(\"process_b\", END)\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "# Main graph nodes\n",
    "@main_graph.node()\n",
    "def start_task(state):\n",
    "    return {\"execution_order\": \"start_task\", \"status\": \"started\"}\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_task(state):\n",
    "    return {\"execution_order\": \"end_task\", \"status\": \"completed\"}\n",
    "\n",
    "\n",
    "# Connect main graph\n",
    "main_graph.add_edge(START, \"start_task\")\n",
    "main_graph.add_edge(\"start_task\", \"processing_subgraph\")\n",
    "main_graph.add_edge(\"processing_subgraph\", \"end_task\")\n",
    "main_graph.add_edge(\"end_task\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "def nested_subgraph():\n",
    "    nested = Graph(state=state)\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task(state):\n",
    "        return {\"execution_order\": \"nested_task\", \"counter\": 1}\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task_2(state):\n",
    "        return {\"execution_order\": \"nested_task_2\", \"counter\": 2}\n",
    "\n",
    "    nested.add_edge(START, \"nested_task\")\n",
    "    nested.add_edge(\"nested_task\", \"nested_task_2\")\n",
    "    nested.add_edge(\"nested_task_2\", END)\n",
    "    return nested\n",
    "\n",
    "\n",
    "# Create parent subgraph containing nested subgraph\n",
    "@main_graph.subgraph()\n",
    "def parent_subgraph():\n",
    "    parent = Graph(state=state)\n",
    "\n",
    "    @parent.node()\n",
    "    def parent_task(state):\n",
    "        return {\"execution_order\": \"parent_task\", \"counter\": 2}\n",
    "\n",
    "    @parent.subgraph()\n",
    "    def inner_nested():\n",
    "        return nested_subgraph()\n",
    "\n",
    "    parent.add_edge(START, \"parent_task\")\n",
    "    parent.add_edge(\"parent_task\", \"inner_nested\")\n",
    "    parent.add_edge(\"inner_nested\", END)\n",
    "    return parent\n",
    "\n",
    "\n",
    "# Main graph setup\n",
    "@main_graph.node()\n",
    "def main_task(state):\n",
    "    return {\"execution_order\": \"main_task\", \"status\": \"running\"}\n",
    "\n",
    "\n",
    "main_graph.add_edge(START, \"main_task\")\n",
    "main_graph.add_edge(\"main_task\", \"parent_subgraph\")\n",
    "main_graph.add_edge(\"parent_subgraph\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Repeated Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_a():\n",
    "    print(\"Node A\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_b():\n",
    "    print(\"Node B\\n\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_c():\n",
    "    print(\"Node C\")\n",
    "\n",
    "\n",
    "# Add a repeat edge that runs node_b 3 times sequentially\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_repeating_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=False)\n",
    "graph.add_edge(\"node_c\", END)\n",
    "\n",
    "# Or run in parallel\n",
    "# graph.add_repeat_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=True)\n",
    "\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 (async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    execution_times: History[float]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "state = StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Simulate CPU-intensive work\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_parallel\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create parallel execution with many repetitions\n",
    "graph.add_edge(START, \"start_task\")\n",
    "graph.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=True\n",
    ")\n",
    "graph.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph.start_async()\n",
    "parallel_time = time.time() - start_time\n",
    "print(f\"Parallel execution time: {parallel_time}\")\n",
    "\n",
    "# Now test sequential execution\n",
    "graph2 = Graph(\n",
    "    state=StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    ")\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Same task as above\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_sequential\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "graph2.add_edge(START, \"start_task\")\n",
    "graph2.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=False\n",
    ")\n",
    "graph2.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph2.start_async()\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "# Parallel execution should be significantly faster\n",
    "assert parallel_time < sequential_time * 0.7  # At least 30% faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_time, sequential_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Router Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "storage = LocalStorage()\n",
    "graph = Graph(\n",
    "    state=TestState(result={}, execution_order=[]), checkpoint_storage=storage\n",
    ")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_a\"\n",
    "    return \"route_b\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    return {\"result\": {\"result\": \"from route B2\"}, \"execution_order\": \"route_b2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_edge(\"route_b2\", \"route_c\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()  # Will pause after process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._update_execution_plan(\n",
    "    \"process_data\", graph.router_paths[\"process_data\"][\"route_a\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths[\"process_data\"][\"route_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_a\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    if True:\n",
    "        return \"route_c\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "# graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_router_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()\n",
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(START, \"route_a\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_b\")\n",
    "graph.add_router_edge(\"route_b\", \"route_c\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.next_execution_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.blocking_execution_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Real World Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandomeira/miniforge3/envs/tiny-graph/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_message\" in State has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List, Any\n",
    "\n",
    "\n",
    "\n",
    "class State(GraphState):\n",
    "    conversation: History[Dict[str, str]]\n",
    "    model_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]]\n",
    "    is_forward_permission: LastValue[Union[bool, None]]\n",
    "    is_permission_granted: LastValue[Union[bool, None]]\n",
    "    is_outside_of_step: LastValue[Union[bool, None]]\n",
    "    plan_goal: LastValue[str]\n",
    "    plan_summary: LastValue[str]\n",
    "    plan_details: History[str]\n",
    "    is_ready_to_move_forward: LastValue[bool]\n",
    "    is_summary_approved: LastValue[bool]\n",
    "    interaction_summary: LastValue[str]\n",
    "    \n",
    "\n",
    "def generate_plan_graph(graph_state: State):\n",
    "    \n",
    "    plan_graph = Graph(graph_state, verbose=False)\n",
    "    \n",
    "\n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    async def intitialize_conversation(state: State) -> dict[str, Any]:\n",
    "        print(\"Initializing conversation...\")\n",
    "        response = \"Welcome! Please tell me your goal in a single sentence.\"\n",
    "    \n",
    "        \n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    async def process_user_message(state: State) -> dict[str, Any]:\n",
    "        print(\"Processing user message...\")\n",
    "        \n",
    "        # Simulated response\n",
    "        response = \"I understand your goal. Let me ask a follow-up question.\"\n",
    "        plan_goal = \"Sample goal\"\n",
    "        plan_details = [\"Detail 1\", \"Detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        # Add sample plan details\n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"plan_goal\": plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def response_router(state: State) -> str:\n",
    "        print(\"Routing response...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        elif state.is_forward_permission:\n",
    "            return 'summarize_and_ask_permission'\n",
    "        return END\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def make_followup_questions(state: State):\n",
    "        print(\"Making follow-up questions...\")\n",
    "        response = \"Here's a follow-up question for clarification.\"\n",
    "        plan_details = [\"Follow-up detail 1\", \"Follow-up detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def check_followup_next_step(state: State):\n",
    "        print(\"Checking follow-up next step...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        return 'summarize_and_ask_permission'\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def summarize_and_ask_permission(state: State):\n",
    "        print(\"Summarizing and asking for permission...\")\n",
    "        response = \"Here's a summary of our discussion. Shall we move forward?\"\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": False,\n",
    "            \"is_permission_granted\": True,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def move_to_next_step(state: State):\n",
    "        print(\"Moving to next step...\")\n",
    "        if state.is_permission_granted:\n",
    "            return END\n",
    "        return 'process_user_message'\n",
    "\n",
    "\n",
    "    plan_graph.add_edge(START, 'intitialize_conversation')\n",
    "    plan_graph.add_edge('intitialize_conversation', 'process_user_message')\n",
    "    plan_graph.add_router_edge('process_user_message', 'response_router')\n",
    "    plan_graph.add_router_edge('make_followup_questions', 'check_followup_next_step')\n",
    "\n",
    "    plan_graph.add_router_edge(\"summarize_and_ask_permission\", \"move_to_next_step\")\n",
    "    \n",
    "    \n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"381pt\" height=\"842pt\"\n",
       " viewBox=\"21.60 21.60 359.10 820.42\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(25.6 816.42)\">\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"227.5\" cy=\"-772.82\" rx=\"47.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"227.5\" y=\"-770.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__start__</text>\n",
       "</g>\n",
       "<!-- intitialize_conversation -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>intitialize_conversation</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M137.5,-689.32C137.5,-689.32 317.5,-689.32 317.5,-689.32 323.5,-689.32 329.5,-695.32 329.5,-701.32 329.5,-701.32 329.5,-713.32 329.5,-713.32 329.5,-719.32 323.5,-725.32 317.5,-725.32 317.5,-725.32 137.5,-725.32 137.5,-725.32 131.5,-725.32 125.5,-719.32 125.5,-713.32 125.5,-713.32 125.5,-701.32 125.5,-701.32 125.5,-695.32 131.5,-689.32 137.5,-689.32\"/>\n",
       "<text text-anchor=\"start\" x=\"139.5\" y=\"-704.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">intitialize_conversation</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"253.5,-689.32 253.5,-725.32 \"/>\n",
       "<text text-anchor=\"start\" x=\"267.5\" y=\"-705.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\"></text>\n",
       "<text text-anchor=\"start\" x=\"274.5\" y=\"-705.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"278.5\" y=\"-705.82\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;intitialize_conversation -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;intitialize_conversation</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.5,-754.58C227.5,-754.58 227.5,-735.47 227.5,-735.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231,-735.47 227.5,-725.47 224,-735.47 231,-735.47\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"64.5\" cy=\"-18\" rx=\"45.34\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.5\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__end__</text>\n",
       "</g>\n",
       "<!-- process_user_message -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>process_user_message</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M281.5,-659.82C281.5,-659.82 173.5,-659.82 173.5,-659.82 167.5,-659.82 161.5,-653.82 161.5,-647.82 161.5,-647.82 161.5,-635.82 161.5,-635.82 161.5,-629.82 167.5,-623.82 173.5,-623.82 173.5,-623.82 281.5,-623.82 281.5,-623.82 287.5,-623.82 293.5,-629.82 293.5,-635.82 293.5,-635.82 293.5,-647.82 293.5,-647.82 293.5,-653.82 287.5,-659.82 281.5,-659.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"227.5\" y=\"-639.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">process_user_message</text>\n",
       "</g>\n",
       "<!-- intitialize_conversation&#45;&gt;process_user_message -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>intitialize_conversation&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.5,-689.08C227.5,-689.08 227.5,-669.97 227.5,-669.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231,-669.97 227.5,-659.97 224,-669.97 231,-669.97\"/>\n",
       "</g>\n",
       "<!-- response_router -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>response_router</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M175.01,-586.59C175.01,-586.59 137.49,-549.06 137.49,-549.06 133.25,-544.82 133.25,-536.33 137.49,-532.09 137.49,-532.09 175.01,-494.57 175.01,-494.57 179.26,-490.32 187.74,-490.32 191.99,-494.57 191.99,-494.57 229.51,-532.09 229.51,-532.09 233.75,-536.33 233.75,-544.82 229.51,-549.06 229.51,-549.06 191.99,-586.59 191.99,-586.59 187.74,-590.83 179.26,-590.83 175.01,-586.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-543.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">response</text>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-532.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">router</text>\n",
       "</g>\n",
       "<!-- process_user_message&#45;&gt;response_router -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>process_user_message&#45;&gt;response_router</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.62,-623.72C199.62,-623.72 199.62,-589.07 199.62,-589.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.12,-589.07 199.62,-579.07 196.12,-589.07 203.12,-589.07\"/>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;__end__ -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M129.44,-540C75.31,-540 0,-540 0,-540 0,-540 0,-18 0,-18 0,-18 9,-18 9,-18\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"9,-21.5 19,-18 9,-14.5 9,-21.5\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>make_followup_questions</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M30,-420.83C30,-420.83 231,-420.83 231,-420.83 237,-420.83 243,-426.83 243,-432.83 243,-432.83 243,-444.83 243,-444.83 243,-450.83 237,-456.83 231,-456.83 231,-456.83 30,-456.83 30,-456.83 24,-456.83 18,-450.83 18,-444.83 18,-444.83 18,-432.83 18,-432.83 18,-426.83 24,-420.83 30,-420.83\"/>\n",
       "<text text-anchor=\"start\" x=\"32\" y=\"-437.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\"></text>\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-437.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"43\" y=\"-437.33\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. before</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"102,-420.83 102,-456.83 \"/>\n",
       "<text text-anchor=\"start\" x=\"116\" y=\"-436.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">make_followup_questions</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M183.5,-486.13C183.5,-486.13 183.5,-466.84 183.5,-466.84\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"187,-466.84 183.5,-456.84 180,-466.84 187,-466.84\"/>\n",
       "</g>\n",
       "<!-- summarize_and_ask_permission -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>summarize_and_ask_permission</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M38,-202.5C38,-202.5 269,-202.5 269,-202.5 275,-202.5 281,-208.5 281,-214.5 281,-214.5 281,-226.5 281,-226.5 281,-232.5 275,-238.5 269,-238.5 269,-238.5 38,-238.5 38,-238.5 32,-238.5 26,-232.5 26,-226.5 26,-226.5 26,-214.5 26,-214.5 26,-208.5 32,-202.5 38,-202.5\"/>\n",
       "<text text-anchor=\"start\" x=\"40\" y=\"-219\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\"></text>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-219\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"51\" y=\"-219\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. before</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"110,-202.5 110,-238.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-218\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">summarize_and_ask_permission</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;summarize_and_ask_permission -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;summarize_and_ask_permission</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M237.59,-540C251.19,-540 262,-540 262,-540 262,-540 262,-248.59 262,-248.59\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"265.5,-248.59 262,-238.59 258.5,-248.59 265.5,-248.59\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>check_followup_next_step</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M122.01,-383.01C122.01,-383.01 77.16,-338.15 77.16,-338.15 72.91,-333.91 72.91,-325.42 77.16,-321.18 77.16,-321.18 122.01,-276.32 122.01,-276.32 126.26,-272.08 134.74,-272.08 138.99,-276.32 138.99,-276.32 183.84,-321.18 183.84,-321.18 188.09,-325.42 188.09,-333.91 183.84,-338.15 183.84,-338.15 138.99,-383.01 138.99,-383.01 134.74,-387.25 126.26,-387.25 122.01,-383.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-343.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">check</text>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-332.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">followup</text>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-321.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">next</text>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-310.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">step</text>\n",
       "</g>\n",
       "<!-- make_followup_questions&#45;&gt;check_followup_next_step -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>make_followup_questions&#45;&gt;check_followup_next_step</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.95,-420.8C109.95,-420.8 109.95,-381.32 109.95,-381.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.45,-381.32 109.95,-371.32 106.45,-381.32 113.45,-381.32\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>check_followup_next_step&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M151.05,-371.25C151.05,-371.25 151.05,-410.74 151.05,-410.74\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"147.55,-410.74 151.05,-420.74 154.55,-410.74 147.55,-410.74\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step&#45;&gt;summarize_and_ask_permission -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>check_followup_next_step&#45;&gt;summarize_and_ask_permission</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M130.5,-267.75C130.5,-267.75 130.5,-248.74 130.5,-248.74\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"134,-248.74 130.5,-238.74 127,-248.74 134,-248.74\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>move_to_next_step</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M145.01,-164.51C145.01,-164.51 107.99,-127.49 107.99,-127.49 103.74,-123.24 103.74,-114.76 107.99,-110.51 107.99,-110.51 145.01,-73.49 145.01,-73.49 149.26,-69.24 157.74,-69.24 161.99,-73.49 161.99,-73.49 199.01,-110.51 199.01,-110.51 203.26,-114.76 203.26,-123.24 199.01,-127.49 199.01,-127.49 161.99,-164.51 161.99,-164.51 157.74,-168.76 149.26,-168.76 145.01,-164.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-133\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">move</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-122\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">to</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-111\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">next</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-100\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">step</text>\n",
       "</g>\n",
       "<!-- summarize_and_ask_permission&#45;&gt;move_to_next_step -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>summarize_and_ask_permission&#45;&gt;move_to_next_step</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.5,-202.35C153.5,-202.35 153.5,-183.12 153.5,-183.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"157,-183.12 153.5,-173.12 150,-183.12 157,-183.12\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step&#45;&gt;__end__ -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>move_to_next_step&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M104.58,-113.85C104.58,-113.85 104.58,-36.53 104.58,-36.53\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"108.08,-36.53 104.58,-26.53 101.08,-36.53 108.08,-36.53\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step&#45;&gt;process_user_message -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>move_to_next_step&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M207.52,-119C244.64,-119 287.25,-119 287.25,-119 287.25,-119 287.25,-613.52 287.25,-613.52\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"283.75,-613.52 287.25,-623.52 290.75,-613.52 283.75,-613.52\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x106a5e590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_graph_state = State(conversation=[], \n",
    "                         model_message=None, \n",
    "                         user_message=None,\n",
    "                         next_interaction={\"worflow_step\": \"user_prompt\"}, \n",
    "                         plan_goal=\"\", \n",
    "                         plan_summary=\"\", \n",
    "                         plan_details=[], \n",
    "                         is_summary_approved=False, \n",
    "                         interaction_summary=\"\", \n",
    "                         is_followup=False,\n",
    "                         is_forward_permission=False,\n",
    "                         is_permission_granted=False,\n",
    "                         is_outside_of_step=False,\n",
    "                         is_ready_to_move_forward=False)\n",
    "\n",
    "graph = generate_plan_graph(plan_graph_state)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing conversation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">State</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Welcome! Please tell me your goal in a single sentence.'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Welcome! Please tell me your goal in a single sentence.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Welcome! Please tell me your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m'Welcome! Please tell me your goal in a single sentence.'\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChainStatus.PAUSE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ChainStatus.PAUSE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">process_user_message\n",
       "</pre>\n"
      ],
      "text/plain": [
       "process_user_message\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await graph.start_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making follow-up questions...\n",
      "Checking follow-up next step...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">State</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Welcome! Please tell me your goal in a single sentence.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I understand your goal. Let me ask a follow-up question.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a follow-up question for clarification.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sample goal'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Follow-up detail 2'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Welcome! Please tell me your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I understand your goal. Let me ask a follow-up question.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a follow-up question for clarification.\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m\"Here\u001b[0m\u001b[32m's a follow-up question for clarification.\"\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m'Sample goal'\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Detail 1'\u001b[0m,\n",
       "        \u001b[32m'Detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 1'\u001b[0m,\n",
       "        \u001b[32m'Follow-up detail 2'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChainStatus.PAUSE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ChainStatus.PAUSE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">make_followup_questions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "make_followup_questions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.is_cyclical_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
