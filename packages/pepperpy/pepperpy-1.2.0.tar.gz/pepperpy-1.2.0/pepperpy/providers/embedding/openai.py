"""OpenAI embedding provider implementation."""

import os
from typing import Any, Dict, List, Optional

import openai
from openai import AsyncOpenAI

from pepperpy.core.utils.errors import ProviderError
from pepperpy.providers.embedding.base import EmbeddingProvider, Embedding, EmbeddingBatch


class OpenAIEmbeddingProvider(EmbeddingProvider):
    """OpenAI embedding provider implementation."""

    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        """Initialize the OpenAI embedding provider.
        
        Args:
            config: Optional configuration dictionary with:
                - api_key: OpenAI API key (optional if set in env)
                - model: Model to use (default: "text-embedding-3-small")
                - dimensions: Output dimension (default: 1536)
                - timeout: Request timeout in seconds (default: 30)
        """
        super().__init__(config)
        self.config = config or {}
        self._client: Optional[AsyncOpenAI] = None
        self._model = self.config.get("model", "text-embedding-3-small")
        self._dimensions = self.config.get("dimensions", 1536)
        self._timeout = self.config.get("timeout", 30)

    async def initialize(self) -> None:
        """Initialize the provider.
        
        This sets up the OpenAI client with the provided configuration.
        
        Raises:
            ProviderError: If initialization fails.
        """
        try:
            api_key = self.config.get("api_key") or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ProviderError("OpenAI API key not found")
                
            self._client = AsyncOpenAI(
                api_key=api_key,
                timeout=self._timeout,
            )
            await super().initialize()
        except Exception as e:
            raise ProviderError(f"Failed to initialize OpenAI provider: {str(e)}") from e

    async def shutdown(self) -> None:
        """Shutdown the provider."""
        if self._client:
            await self._client.close()
        await super().shutdown()

    async def embed_text(self, text: str) -> Embedding:
        """Generate embeddings for a single text.
        
        Args:
            text: Text to generate embeddings for.
            
        Returns:
            Vector representation of the text.
            
        Raises:
            ProviderError: If embedding generation fails.
        """
        if not self._client:
            raise ProviderError("Provider not initialized")
            
        try:
            response = await self._client.embeddings.create(
                model=self._model,
                input=text,
                dimensions=self._dimensions,
            )
            return response.data[0].embedding
        except Exception as e:
            raise ProviderError(f"Failed to generate embedding: {str(e)}") from e

    async def embed_texts(self, texts: List[str]) -> EmbeddingBatch:
        """Generate embeddings for multiple texts.
        
        Args:
            texts: List of texts to generate embeddings for.
            
        Returns:
            List of vector representations.
            
        Raises:
            ProviderError: If embedding generation fails.
        """
        if not self._client:
            raise ProviderError("Provider not initialized")
            
        try:
            response = await self._client.embeddings.create(
                model=self._model,
                input=texts,
                dimensions=self._dimensions,
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            raise ProviderError(f"Failed to generate embeddings: {str(e)}") from e

    async def embed_query(self, query: str) -> Embedding:
        """Generate embeddings for a query.
        
        For OpenAI, query embeddings are the same as document embeddings.
        
        Args:
            query: Query text to generate embeddings for.
            
        Returns:
            Vector representation of the query.
            
        Raises:
            ProviderError: If embedding generation fails.
        """
        return await self.embed_text(query)

    async def get_embedding_dimension(self) -> int:
        """Get the dimension of the embeddings generated by this provider.
        
        Returns:
            Dimension of the embedding vectors.
        """
        return self._dimensions

    async def get_metadata(self) -> Dict[str, Any]:
        """Get provider metadata.
        
        Returns:
            Dictionary containing provider metadata.
        """
        return {
            "model_name": self._model,
            "dimension": self._dimensions,
            "max_length": 8191,  # OpenAI's limit for text-embedding-3-small
            "supports_batching": True,
            "provider_name": "openai",
        } 