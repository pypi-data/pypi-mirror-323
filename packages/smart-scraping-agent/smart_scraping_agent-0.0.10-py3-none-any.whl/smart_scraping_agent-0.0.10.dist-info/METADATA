Metadata-Version: 2.2
Name: smart-scraping-agent
Version: 0.0.10
Summary: Autonomous Scraping Agent: Scrape URLs with prompts and schema
Author-email: Rohan Dhanraj Yadav <rohan.aigroup@gmail.com>
License: MIT License
        
        Copyright (c) 2025 Rohan Dhanraj Yadav
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://github.com/rohan-aigroup/smart_scraper_package
Project-URL: Issues, https://github.com/rohan-aigroup/smart_scraper_package/issues
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: fastapi
Requires-Dist: langchain
Requires-Dist: langchain-community
Requires-Dist: langchain-core
Requires-Dist: langchain-openai
Requires-Dist: langchain-text-splitters
Requires-Dist: markdownify
Requires-Dist: playwright
Requires-Dist: python-dotenv

# SmartScrapingAgent

**SmartScrapingAgent** is a Python package designed to simplify web scraping using state-of-the-art LLMs (Large Language Models) and customizable schemas. With this package, you can extract structured data efficiently from large, complex web pages.

---

## Installation

### Step 1: Install Playwright
Install Playwright, which is required for handling headless browsing:
```bash
playwright install
```

### Step 2: Install SmartScrapingAgent
Install the Smart Scraping Agent package:
```bash
pip install smart-scraping-agent
```

---

## Usage
Here is a step-by-step guide to using the **Smart Scraping Agent** package:

**N.B.: This import is required only for jupyter notebooks, since they have their own eventloop**
```bash
pip install nest-asyncio
```

```python
import nest_asyncio

nest_asyncio.apply()
```


### Step 1: Import Required Modules
Import necessary modules and classes:
```python
import os, json
from dotenv import load_dotenv


load_dotenv()
```


### Step 2: Define the Configuration
Set up the configuration for the scraping pipeline:
```python
agent_config = {
    "llm": {
        "api_key": os.getenv('OPENAI_API_KEY'),
        "model": "openai/gpt-4o-mini",
        # Uncomment for other models
        # "model": "ollama/nemotron-mini",
        # "device": "cuda",
        # "model_kwargs": {'response_format': {"type": "json_object"}}
    },
    "verbose": True,
    "headless": True,
    "max_retries": 3
}
```

### Step 3: Write Your Prompt
Define a simple prompt to guide the scraping process:
```python
simple_prompt = """
Extract all the trending topics, their search volumes, when it started trending and the trend breakdown from the website's content.
"""
```

### Step 4: Load the Schema
Use the schema to define the structure of the extracted data:
Schema can be:
1. `format instruction string with examples`
2. `dict`
3. `json`
4. `pydantic` or `BaseModel`

```python
schema_ = {
    'trends': [
        {
            'topic': 'Trending topic',
            'search_volume': 'Search Volume of a topic',
            'started': 'Time when it started trending',
            'trend_breakdown': 'A trend may consist of multiple queries that are variants of the same search or considered to be related. Trend breakdown details these queries.'
         }
    ],
    'other_links':[
        'list of any other reference URLs'
    ]
}
```

**N.B.**: For better results use a valid `pydantic` schema which is a subclass of `BaseModel`.

### Step 5: Instantiate the SmartScraperAgent
Create an instance of the **SmartScraperAgent** with the necessary parameters:
```python
from smart_scraping_agent import SmartScraperAgent

url = "https://trends.google.com/trending"

smart_scraper_agent = SmartScraperAgent(
    prompt=simple_prompt,
    source=url,
    config=agent_config,
    schema=schema_
)
```

### Step 6: Run the Scraper
Execute the scraping pipeline and process the results:
```python
result = smart_scraper_agent.run()
print(json.dumps(result, indent=4))
```

### Load a Webpage content as Markdown
```python
markdown_content = smart_scraper_agent.get_markdown()
print(markdown_content)
```

### Load recursive webpages and split it into Documents
```python
documents = smart_scraper_agent.load_indepth_and_split(depth=2)
print(documents[0].page_content)
print(documents[0].nmetadata)
```

---

## Key Features
- **LLM-Powered**: Leverage advanced models like GPT for smart data extraction.
- **Schema-Driven**: Flexible schema design to control output format.
- **Headless Browsing**: Playwright integration for efficient, non-visual browsing.
- **Customizable**: Fine-tune the pipeline using configurations and custom merge methods.

---

## Contributing
Contributions are welcome! Feel free to submit issues or pull requests on the [GitHub repository](https://github.com/rohan-aigroup/smart_scraper_package).

---

## License
This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.
