# Example TOML configuration file for parrotflume

[global_options]
temperature = 0.1     # Default temperature for the model
max_tokens = 4096     # Maximum number of tokens to generate
markdown = true       # Enable markdown rendering
latex = true          # Enable LaTeX replacement
color = true          # Enable colored output
color_name = "green"  # ANSI name for colored output

# API providers, the first in the list is used as default
[[api_providers]]
name = "openai"
base_url = "https://api.openai.com/v1/"
api_key = "<yourapikeyhere>"
model = "gpt-4o"
func = true  # Enable function calling

[[api_providers]]
name = "deepseek"
base_url = "https://api.deepseek.com/v1/"
api_key = "<yourapikeyhere>"
model = "deepseek-chat"
func = true  # Enable function calling

[[api_providers]]
name = "llama.cpp"
base_url = "http://localhost:8080/v1/"
api_key = "sk-no-key-required"  # not used, NOT allowed to be empty for llama.cpp
model = ""  # not used, allowed to be empty for llama.cpp
func = false  # Disable function calling, not yet supported by llama.cpp

[[api_providers]]
name = "openrouter"
base_url = "https://openrouter.ai/api/v1/"
api_key = "<yourapikeyhere>"
model = "anthropic/claude-3.5-sonnet:beta"
func = true  # Enable function calling
