{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccbfa5ca",
   "metadata": {},
   "source": [
    "# Text Classification with BERT in TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d89d6",
   "metadata": {},
   "source": [
    "The Large Language Models (LLM) like BERT (published in 2018 [1]) have been a huge progress in the development of Natural Language Processing (NLP). LLM help solving many NLP tasks with state-of-the-art performance.\n",
    "In this article we will show with a practical example how text classification can be performed using BERT, in the two main frameworks used for Deep Learning: TensorFlow and PyTorch. For the BERT part we will use the HuggingFace libraries.\n",
    "In the first part of this article, we will remind (briefly) what is a Large Language Model, how we can use it for Transfer Learning, and how it can be fine-tuned for a specific task like Classification. Then we will prepare the dataset, develop the models and train them in both TensorFlow and PyTorch frameworks. Finally we will compare the two frameworks.\n",
    "We have already published an article to show various methods of Text Classification (https://medium.com/@claude.feldges/text-classification-with-tf-idf-lstm-bert-a-quantitative-comparison-b8409b556cb3). In the present article, we re-use a part of what we have written at that time, so there will be some overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18029ac",
   "metadata": {},
   "source": [
    "# Text Classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e2f7c",
   "metadata": {},
   "source": [
    "The publication of the model BERT in 2018 [1] was a revolution in the NLP world, since Large Language Models like BERT achieve state-of-the-art performance in many NLP tasks. To show how BERT can be used in practice, we develop an example of Text Classification. In these cases, we say that BERT, which contains linguistic capabilities and world knowledge from its numerous sources it was trained with (Wikipedia, books, ...), is used for Transfer Learning, while the Classification exercise we perform is called Fine-Tuning.\n",
    "\n",
    "\"Fine-Tuning\" does not mean that we adjust the BERT model. We use BERT as it is,and add a \"head\" on top of BERT. BERT is used to \"encode\" some properties of a text into a vector (or tensor). The Classification exercise consists then of a Classification of these vectors. The Classification of these encoded values into vectors becomes a classical classification Machine Learning problem, which can be done either with a classical approach (Logistic Regression, Naive Bayes, ...) or with a Neural Network.\n",
    "\n",
    "To be more precise, we will not work with BERT directly, but with DistilBERT, which is a simplified model (having only half of BERT's parameters) which mimicks the behaviour of BERT. DistilBERT's performance is very close to BERT's performance (and sometimes even better), despite having only half of the parameters! For more details about this approach you can read [2]. In the present article, we will use the word BERT most of the time, even if we use DistilBERT.\n",
    "\n",
    "To build a Text Classification model using BERT we can apply two (slightly) different strategies. As mentioned above, BERT is used to encode texts into a vector. The classification model we built on BERT consists of classifying these vectors using ML algorithms. So we can either:\n",
    "- Apply BERT to the texts as a pre-processing steps, then build a ML model that classifies these vectors\n",
    "- Build a model which starts with BERT (where we freeze the parameters when training the model), then build on top of BERT a layer that classifies these vectors\n",
    "\n",
    "The advantage of the first method is that we need to pass the text (training and test data) only once through BERT, and not for each epoch at training, reducing significantly the training time. The advantage of the second method is that we do not need to build an additional step to the pipeline, since the end-to-end (from text to classification) is provided by the tokenizer (see below in the developments what this is) and the model itself.\n",
    "\n",
    "For pedagogical purpose, we will go with the second approach. In a real case, the choice of the approach would depend on the use of the model. If we need to regularly train the model I would favor the first approach. If the model has to be trained only once I would go for the second approach.\n",
    "\n",
    "We will use the DistilBERT model from the Python library transformers, which is provided by the company Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e47d1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36981d1c",
   "metadata": {},
   "source": [
    "In this article we will consider a small dataset: BBC news, classified by topic: https://www.kaggle.com/sainijagjit/bbc-dataset. This corpus contains around 2k entries, which is small enough to be run on a standard computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eb9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries needed for data preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download the dataset and put it in subfolder called data\n",
    "datapath = \"data/bbc-text.csv\"\n",
    "df = pd.read_csv(datapath)\n",
    "df = df[[\"category\", \"text\"]]\n",
    "\n",
    "# Show the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84543346",
   "metadata": {},
   "source": [
    "Let's analyse the data before doing any Text Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5475a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal number of news: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m)))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m40\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplit by category:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('Total number of news: {}'.format(len(df)))\n",
    "print(40*'-')\n",
    "print('Split by category:')\n",
    "print(df[\"category\"].value_counts())\n",
    "print(40*'-')\n",
    "nr_categories = len(df[\"category\"].unique())\n",
    "print(\"Number of categories: {n}\".format(n=nr_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54e15e",
   "metadata": {},
   "source": [
    "We get a total number of entries of 2'225, which are relatively evenly split across five categories. This allows us to apply standard methods, as there is no need to over- or under-weight some categories.\n",
    "\n",
    "Finally, let's look at a specific example to get a concrete impression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4368dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  entertainment\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text:\n",
      "housewives lift channel 4 ratings the debut of us television hit desperate housewives has helped lift channel 4 s january audience share by 12% compared to last year.  other successes such as celebrity big brother and the simpsons have enabled the broadcaster to surpass bbc two for the first month since last july. bbc two s share of the audience fell from 11.2% to 9.6% last month in comparison with january 2004. celebrity big brother attracted fewer viewers than its 2002 series.  comedy drama desperate housewives managed to pull in five million viewers at one point during its run to date  attracting a quarter of the television audience. the two main television channels  bbc1 and itv1  have both seen their monthly audience share decline in a year on year comparison for january  while five s proportion remained the same at a slender 6.3%. digital multi-channel tv is continuing to be the strongest area of growth  with the bbc reporting freeview box ownership of five million  including one million sales in the last portion of 2004. its share of the audience soared by 20% in january 2005 compared with last year  and currently stands at an average of 28.6%.\n"
     ]
    }
   ],
   "source": [
    "# You can adjust n:\n",
    "n=100\n",
    "print('Category: ',df['category'][n])\n",
    "print(100*'-')\n",
    "print('Text:')\n",
    "print(df['text'][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4126e90",
   "metadata": {},
   "source": [
    "For Large Language Models (LLM), there is no need to further manually process the data, since tokenizers, i.e. the layers that encode text into \"numbers\" comes with the model.\n",
    "\n",
    "The label has to be converted to a number, an \"index\". Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07d23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 3 ... 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Renaming, Input -> X, Output -> y\n",
    "X = df['text']\n",
    "y=np.unique(df['category'], return_inverse=True)[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0bf3c",
   "metadata": {},
   "source": [
    "Let's also instantiate the BERT tokenizer that will be used later. The same tokenizer can be used for both frameworks TensorFlow and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878bc628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/gomtm/mtmai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# distilBERT tokenizer\n",
    "import transformers\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fd6f5",
   "metadata": {},
   "source": [
    "From now we will distinguish between  TensorFlow and PyTorch. The principles are still the same, however the nature of the objects will change. TensorFlow and PyTorch both have their own tensor objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e794d",
   "metadata": {},
   "source": [
    "# Building a Text Classification in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce4542",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff753e",
   "metadata": {},
   "source": [
    "Let's note that TensorFlow has its own Tensors (TensorFlow tensors), and its own dataset types. But the TensorFlow framework can also be used with NumPy arrays, which is in my view simpler to use. This is what we are going to use in the present example. It is a significant difference with PyTorch, where we are almost forced to use PyTorch tensors, PyTorch datasets, and PyTorch dataloader.\n",
    "\n",
    "We will first convert the input data (the text) into NumPy arrays, using DistilBERT's tokenizer.\n",
    "\n",
    "We will also split the dataset into a train and a test dataset. When doing this we take care of keeping the same proportions by category between the training and the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665f1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_tf = [tokenizer(text, padding='max_length', max_length = 512, truncation=True)['input_ids'] for text in X]\n",
    "X_tf = np.array(X_tf, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b342fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (1557, 512)\n",
      "Shape of test data:  (668, 512)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tf_train, X_tf_test, y_tf_train, y_tf_test = train_test_split(X_tf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print('Shape of training data: ',X_tf_train.shape)\n",
    "print('Shape of test data: ',X_tf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c0a93",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd2f70",
   "metadata": {},
   "source": [
    "Let's build the model. For this we first need to get the BERT layer from the transformer library. We configure it such that its parameters will not be trained during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709fa7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Get BERT layer\n",
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "dbert_tf = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd40bfb",
   "metadata": {},
   "source": [
    "You might get a warning message. Don't worry about it. In the context where we apply the model, this message can be ignored.\n",
    "\n",
    "Let's try to better understand this model by having a closer look at its output. For this, let's take a sample from our training dataset (we take a sample of size five) and look at the output through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d207faad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type:  <class 'transformers.modeling_tf_outputs.TFBaseModelOutput'>\n",
      "Output format (shape):  (5, 512, 768)\n",
      "Output used as input for the classifier (shape):  (5, 768)\n"
     ]
    }
   ],
   "source": [
    "#Â Let's create a sample of size 5 from the training data\n",
    "sample = X_tf_train[0:5]\n",
    "print('Object type: ', type(dbert_tf(sample)))\n",
    "print('Output format (shape): ',dbert_tf(sample)[0].shape)\n",
    "print('Output used as input for the classifier (shape): ', dbert_tf(sample)[0][:,0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d47ca",
   "metadata": {},
   "source": [
    "The output is a specific Python object. Among other information, we get a Tensor of size (N, M, S), where N is the size of the dataset (in our case five examples), M is the length of the sample (number of words in the text), and S is the size of the output vector (the output of the model). Typically, as mentioned by Devlin et al. [1] for a classification task, we use the first output vector of a sentence as input for the rest of the classification model, since this first vector \"encodes\" information about the overall text. Alternatively a pooling average of all output vectors could also be used as input for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb83f78",
   "metadata": {},
   "source": [
    "It is now time to build the classification model! It will consist of:\n",
    "- Input layer: to tell the model which input format to expect, so that the model knows what to expect. This is specific to TensorFlow\n",
    "- Distil Bert model: to encode the input data into a new sequence of vectors (that is the output of BERT). Only the first vector of this sequence will be used as an input for the rest of the classifier\n",
    "- Dropout layer: for regularization\n",
    "- Dense layer (with relu activation function, with 64 neurons): to solve the specific problem of classification\n",
    "- Dense layer (with softmax activation function): for a probability distribution for each label\n",
    "\n",
    "The Dropout layer is used only during training. Some links between the layers are set to zero on purpose, so that its \"neighbours\" take over its role. This makes the overall prediction more robust. When using the model for inference (prediction), the dropout layers are ignored and the output is re-scaled accordingly. Note that this is one of the reasons why we have to tell the model whether it is in training or in evaluation mode.\n",
    "\n",
    "In TensorFlow we also need to \"compile\" the model, providing it with the optimizer, the loss, and the metrics to be used for training. There are standards for these three objects, which can be entered in the form of text ('adam', 'sparse_categorical_crossentropy', 'accuracy'). But all these three object types can also be instantiated as objects, and then customized.\n",
    "\n",
    "After creating the model we will look at it via the summary function of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ee42891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, metrics\n",
    "\n",
    "input_ids_in = layers.Input(shape=(512,), name='input_token', dtype='int32')\n",
    "\n",
    "x = dbert_tf(input_ids=input_ids_in)[0][:,0,:]\n",
    "x = layers.Dropout(0.2, name='dropout')(x)\n",
    "x = layers.Dense(64, activation='relu', name='dense')(x)\n",
    "x = layers.Dense(5, activation='softmax', name='classification')(x)\n",
    "\n",
    "model_tf = models.Model(inputs=input_ids_in, outputs = x, name='ClassificationModelTF')\n",
    "\n",
    "model_tf.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=[metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dffcb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ClassificationModelTF\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_token (InputLayer)    [(None, 512)]             0         \n",
      "                                                                 \n",
      " tf_distil_bert_model (TFDis  TFBaseModelOutput(last_h  66362880 \n",
      " tilBertModel)               idden_state=(None, 512,             \n",
      "                             768),                               \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 768)              0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                49216     \n",
      "                                                                 \n",
      " classification (Dense)      (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,412,421\n",
      "Trainable params: 49,541\n",
      "Non-trainable params: 66,362,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6abb0",
   "metadata": {},
   "source": [
    "Let's quickly check if the number of trainable parameters (which are only in the dense layers, BERT being \"frozen\") makes sense.\n",
    "The vector that comes out of BERT is one vector of size 768 (by definition of the BERT model). Each of these elements are linked to each of the 64 neurons of the dense layer, leading to 768x64=49'152 parameters. Each neuron has an additional parameter, the bias, i.e. 64 parameters. The output of the dense layer consists of 64 elements, that connect to all the five elements of the classification layer, i.e. 64x5. The classification layer also has 5 bias. \n",
    "\n",
    "In total, the number of trainable parameters is: 768x64+64+64*5+5 = 49'541! We are there :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa6de9",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e1368",
   "metadata": {},
   "source": [
    "It is now time to train the model! Let's do it by keeping in mind that we want to measure the performance (both in terms of accuracy as well as training time), so let's put the measurement in place.\n",
    "\n",
    "TensorFlow has a very practical way of training its models, in a few lines of code. The model \"fits\" the training data, similar as the scikit learn library does. The training process also keeps track of some intermediate data, which allows us to monitor the progress of the training. This comfort comes however at the cost of less transparency about the training itself. We will see later that PyTorch is different in this regard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ded9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 769s 16s/step - loss: 0.9628 - sparse_categorical_accuracy: 0.6930 - val_loss: 0.4008 - val_sparse_categorical_accuracy: 0.9207\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 773s 16s/step - loss: 0.3232 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.1771 - val_sparse_categorical_accuracy: 0.9536\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 790s 16s/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.1264 - val_sparse_categorical_accuracy: 0.9611\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 839s 17s/step - loss: 0.1492 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 844s 17s/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Train the model\n",
    "start_time = datetime.now()\n",
    "history = model_tf.fit(X_tf_train, y_tf_train, batch_size=32, shuffle=True, epochs=5, validation_data=(X_tf_test, y_tf_test))\n",
    "end_time = datetime.now()\n",
    "\n",
    "training_time_tf = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f014771a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd70820fed0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "ax[0].set(title='Loss')\n",
    "ax[0].plot(history.history['loss'], label='Training')\n",
    "ax[0].plot(history.history['val_loss'], label='Validation')\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "ax[1].set(title='Accuracy')\n",
    "ax[1].plot(history.history['sparse_categorical_accuracy'], label='Training')\n",
    "ax[1].plot(history.history['val_sparse_categorical_accuracy'], label='Validation')\n",
    "ax[1].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a69efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 95.4%\n",
      "Accuracy Test data: 97.0%\n",
      "Training time: 4015.3s (or 66.9 minutes)\n"
     ]
    }
   ],
   "source": [
    "accuracy_tf = history.history['val_sparse_categorical_accuracy'][-1]\n",
    "print('Accuracy Training data: {:.1%}'.format(history.history['sparse_categorical_accuracy'][-1]))\n",
    "print('Accuracy Test data: {:.1%}'.format(history.history['val_sparse_categorical_accuracy'][-1]))\n",
    "print('Training time: {:.1f}s (or {:.1f} minutes)'.format(training_time_tf, training_time_tf/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793215e",
   "metadata": {},
   "source": [
    "The training time is above one hour (on a CPU) and the accuracy looks good (>95%)! We also observe that the accuracy increases with the epochs, and the trianing and validation accuracies are close to each other, meaning there seems to be no overfitting. We will not look further into the entries that produced the wrong prediction, since this is not the goal of this article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fc0e0",
   "metadata": {},
   "source": [
    "The model has been trained. Now it is time to save the model! If we do not perform this step, all our training effort will be lost..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04723982",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e652900",
   "metadata": {},
   "source": [
    "We can save the model in the format proposed by TensofFlow (extension: h5). We need an additional step, since we are using a custom object (the BERT layer, which comes from the library Hugging Face). See how we can save the model, and load it in a new model. Note that when doing this we lose some properties (like having non-trainable parameters). Be careful when doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d357b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.save('model_tf.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "061e8b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ClassificationModelTF\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_token (InputLayer)    [(None, 512)]             0         \n",
      "                                                                 \n",
      " tf_distil_bert_model_3 (TFD  TFBaseModelOutput(last_h  66362880 \n",
      " istilBertModel)             idden_state=(None, 512,             \n",
      "                             768),                               \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 768)              0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                49216     \n",
      "                                                                 \n",
      " classification (Dense)      (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,412,421\n",
      "Trainable params: 66,412,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tf2 = models.load_model('model_tf.h5', custom_objects={'TFDistilBertModel': dbert_tf})\n",
    "model_tf2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe7fcf",
   "metadata": {},
   "source": [
    "# Building a Text Classification in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b4a37",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39657180",
   "metadata": {},
   "source": [
    "Let's remember that we have already prepared the dataset (see above, under Dataset). We have also already instantiated a Tokenizer (that is universal across TensorFlow and PyTorch). What we still need to do is customize the dataset to PyTorch. PyTorch has a class for this purpose (classes Dataset and DataLoader). To my knowledge it is mandatory to use Datasets and Dataloaders to train a model. We cannot train a model using NumPy arrays.\n",
    "\n",
    "In a first step we will convert the dataset into torch tensors, then pack them into a Dataset class, and finally embed the Dataset into a Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86bb87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_list=X.to_list()\n",
    "X_pt = tokenizer(X_list, padding='max_length', max_length = 512, truncation=True, return_tensors='pt')[\"input_ids\"]\n",
    "\n",
    "y_list=y.tolist()\n",
    "y_pt = torch.Tensor(y_list).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4938377",
   "metadata": {},
   "source": [
    "Let's split the dataset into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f442ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt_train, X_pt_test, y_pt_train, y_pt_test = train_test_split(X_pt, y_pt, test_size=0.3, random_state=42, stratify=y_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c239ba",
   "metadata": {},
   "source": [
    "We create a Dataset class and will instantiate for both the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "13c0cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class BBCNewsDataset(Dataset):\n",
    "    \"\"\"Custom-built BBC News dataset\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X, y as Torch tensors\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "836f27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data in form of Dataset class\n",
    "train_data_pt = BBCNewsDataset(X=X_pt_train, y=y_pt_train)\n",
    "test_data_pt = BBCNewsDataset(X=X_pt_test, y=y_pt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21adeaf",
   "metadata": {},
   "source": [
    "We embed the datasets into a dataloader, to prepare the dataset to be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aed97211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data in form of Dataloader class\n",
    "train_loader_pt = DataLoader(train_data_pt, batch_size=32)\n",
    "test_loader_pt = DataLoader(test_data_pt, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb1f28",
   "metadata": {},
   "source": [
    "We are now done with the preparation of the dataset! It was a bit more effort than for TensorFlow, but it is worth using the framework PyTorch offers for datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806a758",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30b5b4",
   "metadata": {},
   "source": [
    "From now we will follow very closely the approach we have used for TensorFlow and try to stick to the same parameters wherever it is possible.\n",
    "\n",
    "Let's build the model. For this we first need to get the BERT layer from the transformer library. We configure it such that its parameters will not be trained during training.\n",
    "\n",
    "Note that we have already defined a config object while building the TensorFlow model. The first line below is therefore not needed. We have added just to allow you to run both models (TensorFlow and PyTorch) independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1eed45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "dbert_pt = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e7a0d",
   "metadata": {},
   "source": [
    "You might get a warning message. Don't worry about it. In the context where we apply the model, this message can be ignored.\n",
    "\n",
    "Let's try to better understand this model by having a closer look at its output. For this, let's take a sample from our training dataset (we take a sample of size five) and look at the output through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "69f0737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type:  <class 'transformers.modeling_outputs.BaseModelOutput'>\n",
      "Output format (shape):  torch.Size([5, 512, 768])\n",
      "Output used as input for the classifier (shape):  torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "#Â Let's create a sample of size 5 from the training data\n",
    "sample = X_pt_train[0:5]\n",
    "print('Object type: ', type(dbert_pt(sample)))\n",
    "print('Output format (shape): ',dbert_pt(sample)[0].shape)\n",
    "print('Output used as input for the classifier (shape): ', dbert_pt(sample)[0][:,0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27fcea",
   "metadata": {},
   "source": [
    "Great news! We get the same format as with TensorFlow. But you can see that this time, the tensor is a torch tensor.\n",
    "\n",
    "The output is a specific Python object. Among other information, we get a Tensor of size (N, M, S), where N is the size of the dataset (in our case five examples), M is the length of the sample (number of words in the text), and S is the size of the output vector (the output of the model). Typically, as mentioned by Devlin et al. [1], for a classification task, we use the first output vector of a sentence as input for the rest of the classification model, since this first vector \"encodes\" information about the overall sentence. Alternatively a pooling average of all output vectors could also be used as input for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad8615",
   "metadata": {},
   "source": [
    "It is now time to build the classification model! It will consist of:\n",
    "\n",
    "- Distil Bert model: to encode the input data into a new sequence of vectors (that is the output of BERT). Only the first vector of this sequence will be used as an input for the rest of the classifier\n",
    "- Dropout layer: for regularization\n",
    "- Dense layer (with relu activation function, with 64 neurons): to solve the specific problem of classification\n",
    "- Dense layer (with softmax activation function): for a probability distribution for each label\n",
    "\n",
    "The Dropout layer is used only during training. Some links between the layers are set to zero on purpose, so that its \"neighbours\" take over its role. This makes the overall prediction more robust. When using the model for inference (prediction), the dropout layers are ignored and the output is re-scaled accordingly. Note that this is one of the reasons why we have to tell the model whether it is in training or in evaluation mode.\n",
    "\n",
    "In PyTorch we need to define the layers, and then define a forward function that makes use of the layers. Unlike TensorFlow, we do not add an Input Layer. Remember, TensorFlow needed an Input layer to know what will be the size of the various tensors. In the case of PyTorch, each layer gets the Input size and the Output size as confugration parameters, so the information about the dimensions of the tensors is already contained in the model itself. For example, the layer \"linear1\" gets a vector of size 768 as input, and returns a vector of size 64 as output. These two numbers are part of its definition.\n",
    "\n",
    "Note as well that in PyTorch we do not define a softmax layer (which would be used to normalize the output, so that the total output sums to 1). Instead the nature of the output (which is a probability and therefore needs to sum to 1) will be included in the definition of the criterion (see below under training).\n",
    "\n",
    "After creating the model we will look at it via the print function of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "98d6f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class DistilBertClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBertClassification, self).__init__()\n",
    "        self.dbert = dbert_pt\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(768,64)\n",
    "        self.ReLu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64,5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dbert(input_ids=x)\n",
    "        x = x[\"last_hidden_state\"][:,0,:]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.ReLu(x)\n",
    "        logits = self.linear2(x)\n",
    "        # No need for a softmax, because it is already included in the CrossEntropyLoss\n",
    "        return logits\n",
    "\n",
    "model_pt = DistilBertClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4301017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertClassification(\n",
      "  (dbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
      "  (ReLu): ReLU()\n",
      "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548a96a",
   "metadata": {},
   "source": [
    "We still need to define the parameters of the BERT part of the model to \"not trainable\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "146a2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_pt.dbert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee478b99",
   "metadata": {},
   "source": [
    "Let's look at the number of parameters (trainable and non-trainable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "626ee886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  66412421\n",
      "Number of trainable parameters:  49541\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_pt.parameters())\n",
    "total_params_trainable = sum(p.numel() for p in model_pt.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", total_params)\n",
    "print(\"Number of trainable parameters: \", total_params_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e6cf1",
   "metadata": {},
   "source": [
    "Awesome! We get the same total number of parameters and number of trainable parameters than for the TensorFlow model. So we are probably not totally wrong! For the reader who skipped the TensorFlow section, we reproduce the analysis on the number of parameters:\n",
    "\n",
    "Let's quickly check if the number of trainable parameters (which are only in the dense layers, BERT being \"frozen\") makes sense. The vector that comes out of BERT is one vector of size 768 (by definition of the BERT model). Each of these elements are linked to each of the 64 neurons of the dense layer, leading to 768x64=49'152 parameters. Each neuron has an additional parameter, the bias, i.e. 64 parameters. The output of the dense layer consists of 64 elements, that connect to all the five elements of the classification layer, i.e. 64x5. The classification layer also has 5 bias.\n",
    "\n",
    "In total, the number of trainable parameters is: 768x64+64+64*5+5 = 49'541! We are there :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50f9ed",
   "metadata": {},
   "source": [
    "##Â Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b423f5",
   "metadata": {},
   "source": [
    "It is now time to train the model! Let's do it by keeping in mind that we want to measure the performance (both in terms of accuracy as well as training time), so let's put the measurement in place.\n",
    "\n",
    "At this stage we will notice a fundamental difference between PyTorch and TensorFlow. While TensorFlow has a \"fit\" method that allows training within a couple of lines of code, PyTorch requires more effort: we need to define ourselves a training loop, that will loop over epochs (high level) and batches (low level). But by coding the training loops ourselves, this provides us fully transparency on what is being done!\n",
    "\n",
    "We want to track the progress of the training, similar to what is readily available in TensorFlow. This is why we introduce the dictionary \"history\", that collects various key performance indicators during the training.\n",
    "\n",
    "Before we start training we need to configure the number of epochs, the criterion (what is the function to minimize), and the optimizer.\n",
    "\n",
    "Please go through the code below, which should be self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9077062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_pt.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3cdac1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 49/49 [08:46<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss:      1.099 \t\t Validation Loss:      0.537\n",
      "\t\t Training Accuracy:    67.373% \t\t Validation Accuracy:    90.419%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 49/49 [08:31<00:00, 10.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 \t\t Training Loss:      0.414 \t\t Validation Loss:      0.224\n",
      "\t\t Training Accuracy:    91.908% \t\t Validation Accuracy:    94.910%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 49/49 [09:38<00:00, 11.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 \t\t Training Loss:      0.220 \t\t Validation Loss:      0.155\n",
      "\t\t Training Accuracy:    95.440% \t\t Validation Accuracy:    94.760%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 49/49 [09:16<00:00, 11.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 \t\t Training Loss:      0.174 \t\t Validation Loss:      0.130\n",
      "\t\t Training Accuracy:    95.633% \t\t Validation Accuracy:    95.210%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 49/49 [09:18<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 \t\t Training Loss:      0.143 \t\t Validation Loss:      0.109\n",
      "\t\t Training Accuracy:    96.596% \t\t Validation Accuracy:    96.407%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Define the dictionary \"history\" that will collect key performance indicators during training\n",
    "history = {}\n",
    "history[\"epoch\"]=[]\n",
    "history[\"train_loss\"]=[]\n",
    "history[\"valid_loss\"]=[]\n",
    "history[\"train_accuracy\"]=[]\n",
    "history[\"valid_accuracy\"]=[]\n",
    "\n",
    "# Measure time for training\n",
    "start_time = datetime.now()\n",
    "\n",
    "#Â Loop on epochs\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Set mode in train mode\n",
    "    model_pt.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_accuracy = []\n",
    "    \n",
    "    #Â Loop on batches\n",
    "    for X, y in tqdm(train_loader_pt):\n",
    "        \n",
    "        # Get prediction & loss\n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "        \n",
    "        # Adjust the parameters of the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        train_accuracy += accuracy\n",
    "    \n",
    "    train_accuracy = (sum(train_accuracy) / len(train_accuracy)).item()\n",
    "    \n",
    "    # Calculate the loss on the test data after each epoch\n",
    "    # Set mode to evaluation (by opposition to training)\n",
    "    model_pt.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = []\n",
    "    for X, y in test_loader_pt:\n",
    "         \n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        valid_accuracy += accuracy\n",
    "    valid_accuracy = (sum(valid_accuracy) / len(valid_accuracy)).item()\n",
    "    \n",
    "    # Populate history\n",
    "    history[\"epoch\"].append(e+1)\n",
    "    history[\"train_loss\"].append(train_loss / len(train_loader_pt))\n",
    "    history[\"valid_loss\"].append(valid_loss / len(test_loader_pt))\n",
    "    history[\"train_accuracy\"].append(train_accuracy)\n",
    "    history[\"valid_accuracy\"].append(valid_accuracy)    \n",
    "        \n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader_pt) :10.3f} \\t\\t Validation Loss: {valid_loss / len(test_loader_pt) :10.3f}')\n",
    "    print(f'\\t\\t Training Accuracy: {train_accuracy :10.3%} \\t\\t Validation Accuracy: {valid_accuracy :10.3%}')\n",
    "    \n",
    "# Measure time for training\n",
    "end_time = datetime.now()\n",
    "training_time_pt = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "69e224a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd708b60610>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "ax[0].set(title='Loss')\n",
    "ax[0].plot(history['train_loss'], label='Training')\n",
    "ax[0].plot(history['valid_loss'], label='Validation')\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "ax[1].set(title='Accuracy')\n",
    "ax[1].plot(history['train_accuracy'], label='Training')\n",
    "ax[1].plot(history['valid_accuracy'], label='Validation')\n",
    "ax[1].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ebc41a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 96.6%\n",
      "Accuracy Test data: 96.4%\n",
      "Training time: 3604.6s (or 60.1 minutes)\n"
     ]
    }
   ],
   "source": [
    "accuracy_pt = history['valid_accuracy'][-1]\n",
    "print('Accuracy Training data: {:.1%}'.format(history['train_accuracy'][-1]))\n",
    "print('Accuracy Test data: {:.1%}'.format(history['valid_accuracy'][-1]))\n",
    "print('Training time: {:.1f}s (or {:.1f} minutes)'.format(training_time_pt, training_time_pt/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e99c1",
   "metadata": {},
   "source": [
    "The training time lasts one hour (on a CPU), making it faster than TensorFlow. It is to note that we ran the training several times and observed fluctuations in the duration of the order of 10%. The accuracy looks good (>95%)! We also observe that the accuracy increases with the epochs, and the trianing and validation accuracies are close to each other, meaning there seems to be no overfitting. We will not look further into the entries that produced the wrong prediction, since this is not the goal of this article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964c53c",
   "metadata": {},
   "source": [
    "Our model is trained! To keep this model, let's save it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6dce05",
   "metadata": {},
   "source": [
    "##Â Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f24561",
   "metadata": {},
   "source": [
    "There are two approaches to save a model and we will cover both in this section.\n",
    "\n",
    "It is possible to save only the parameters of the model. Then, to load the model, we will first have to instantiate the model (the model DistilBertClassification), then load all its (trained) parameters into this model. This is a convenient way of storing a model, however it is only possible if you have full details about the architecture of the original model.\n",
    "\n",
    "An alternative is to save the entire model. By doing so it is easier to load the model from its saved location. Let's look at the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bec5232c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassification(\n",
       "  (dbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (ReLu): ReLU()\n",
       "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save only the parameters of the model but not the model itself, and get it back\n",
    "torch.save(model_pt.state_dict(), 'PyModel.sd')\n",
    "model_reloaded = DistilBertClassification()\n",
    "model_reloaded.load_state_dict(torch.load('PyModel.sd'))\n",
    "model_reloaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f5c07c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassification(\n",
       "  (dbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (ReLu): ReLU()\n",
       "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the entire model, and get it back\n",
    "torch.save(model_pt, 'PyModelComplete.pt')\n",
    "model_reloaded2 = torch.load('PyModelComplete.pt')\n",
    "model_reloaded2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429e9c9",
   "metadata": {},
   "source": [
    "# Comparison TensorFlow vs. PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db5dd5",
   "metadata": {},
   "source": [
    "We have gone through a classification model using the pre-trained model BERT, and fine-tuning it for the Classificaiton exercise. We have done this in both frameworks TensorFlow and PyTorch. In the present section we highlight the main differences between the two frameworks. A comparison will always contain some subjectivity, therefore please be aware that what follows represent mainly my opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a337860",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bafbc2",
   "metadata": {},
   "source": [
    "When preparing the data, TensorFlow has proven to be very versatile, as it is possible to use NumPy arrays, which is a format in which many datasets are available, and is very easy to manipulate. TensorFlow also has its own tensors (TensorFlow tensors), and its own datasets formats (which we have not covered in this article, you can find details in [ref], chapter [ref]). PyTorch, to the best of our knowledge, requires the use of its own PyTorch tensors, datasets, and dataloaders. This makes the preparation of datasets more rigorous, but this definitely comes at the costs of less flexibility.\n",
    "\n",
    "For training, TensorFlow offers a high level framework (Keras), which makes training especially easy, using a \"fit\" function similar to what all Machine Learning engineers know from the scikit learn framework. With TensorFlow it is possible to go to a lower level when training, however not at a level PyTorch offers. In PyTorch, training has to be prepared yourself, at a low level where even the loops over epochs and batches need be defined. The various steps of training (forward, backward, adjustment of parameters) is done in a very granular manner. When training in PyTorch, we get the feeling that \"we know what is happening\", which is very positive. But unfortunately, there is no high level framework available in PyTorch (as far as we know), which would allow to quickly experiment new models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf526a",
   "metadata": {},
   "source": [
    "## Training & Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb125749",
   "metadata": {},
   "source": [
    "In addition to assessing the difference in programming in both frameworks, let's analyze the training time and the models themselves, especially the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "22f567ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_89e11_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Framework</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >Training Time [s]</th>        <th class=\"col_heading level0 col3\" >Training Time [% from best]</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_89e11_row0_col0\" class=\"data row0 col0\" >TensorFlow</td>\n",
       "                        <td id=\"T_89e11_row0_col1\" class=\"data row0 col1\" >97.0%</td>\n",
       "                        <td id=\"T_89e11_row0_col2\" class=\"data row0 col2\" >4015.3</td>\n",
       "                        <td id=\"T_89e11_row0_col3\" class=\"data row0 col3\" >11.4%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_89e11_row1_col0\" class=\"data row1 col0\" >PyTorch</td>\n",
       "                        <td id=\"T_89e11_row1_col1\" class=\"data row1 col1\" >96.4%</td>\n",
       "                        <td id=\"T_89e11_row1_col2\" class=\"data row1 col2\" >3604.6</td>\n",
       "                        <td id=\"T_89e11_row1_col3\" class=\"data row1 col3\" >0.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd70bfb22d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "framework = ['TensorFlow', 'PyTorch']\n",
    "accuracy = [accuracy_tf, accuracy_pt]\n",
    "accuracy = [str(round(acc*100, 1))+'%' for acc in accuracy]\n",
    "training_time = [round(training_time_tf,1), round(training_time_pt,1)]\n",
    "training_time_rounded = [str(round(tt,1)) for tt in training_time]\n",
    "training_time = np.array(training_time)\n",
    "training_time_x = list((training_time/min(training_time)-1)*100)\n",
    "training_time_x = [str(round(ttx,1))+'%' for ttx in training_time_x]\n",
    "\n",
    "dict = {'Framework' : framework,\n",
    "        'Accuracy' : accuracy,\n",
    "        'Training Time [s]' : training_time_rounded,\n",
    "        'Training Time [% from best]' : training_time_x}\n",
    "df = pd.DataFrame(dict)\n",
    "display(df.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503d593",
   "metadata": {},
   "source": [
    "The training time is for both frameworks at around one hour, slightly faster for PyTorch than for TensorFlow. The accuracy is slightly better for TensorFlow than for PyTorch. Overall, we can consider that both frameworks have a similar performance, in both training time and accuracy. There is no meaningful difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0854467",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96519d7b",
   "metadata": {},
   "source": [
    "[1]: Devlin et al. (2018). âBERT: Pre-training of Deep Bidirectional Transformers for Language Understandingâ (https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "[2]: V. Sanh et al (2019), \"DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter\" (https://arxiv.org/abs/1910.01108)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
